name: Production Pipeline

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
    types: [opened, synchronize, reopened]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}
  PYTHON_VERSION: "3.11"
  NODE_VERSION: "18"
  TERRAFORM_VERSION: "1.6.0"

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # Security Scanning Stage
  security-scan:
    name: Security Scanning
    runs-on: ubuntu-latest
    permissions:
      contents: read
      security-events: write
      actions: read
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'
          severity: 'CRITICAL,HIGH'

      - name: Upload Trivy scan results to GitHub Security
        uses: github/codeql-action/upload-sarif@v2
        with:
          sarif_file: 'trivy-results.sarif'

      - name: Run Snyk Security Scan
        uses: snyk/actions/node@master
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
        with:
          args: --severity-threshold=high --all-projects

      - name: Run GitLeaks (Secret Scanning)
        uses: gitleaks/gitleaks-action@v2
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: SAST with Semgrep
        uses: returntocorp/semgrep-action@v1
        with:
          config: >-
            p/security-audit
            p/python
            p/typescript
            p/javascript
            p/dockerfile
            p/kubernetes

      - name: License Compliance Check
        uses: fossa-contrib/fossa-action@v2
        with:
          api-key: ${{ secrets.FOSSA_API_KEY }}

  # Code Quality Analysis
  code-quality:
    name: Code Quality Analysis
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: SonarCloud Scan
        uses: SonarSource/sonarcloud-github-action@master
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Python Code Quality
        run: |
          pip install black flake8 mypy bandit safety
          black --check backend/
          flake8 backend/
          mypy backend/
          bandit -r backend/
          safety check -r backend/requirements.txt

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Frontend Code Quality
        run: |
          cd frontend
          npm ci
          npm run lint
          npm run type-check

  # Unit Tests
  test-unit:
    name: Unit Tests
    needs: [security-scan, code-quality]
    runs-on: ubuntu-latest
    strategy:
      matrix:
        service: [frontend, backend]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        if: matrix.service == 'backend'
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Setup Node.js
        if: matrix.service == 'frontend'
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: |
            ~/.cache/pip
            ~/.npm
            frontend/node_modules
          key: ${{ runner.os }}-${{ matrix.service }}-${{ hashFiles('**/requirements.txt', '**/package-lock.json') }}

      - name: Run Backend Tests
        if: matrix.service == 'backend'
        run: |
          cd backend
          pip install -r requirements.txt -r requirements-dev.txt
          pytest tests/unit/ --cov=app --cov-report=xml --cov-report=html

      - name: Run Frontend Tests
        if: matrix.service == 'frontend'
        run: |
          cd frontend
          npm ci
          npm run test:unit -- --coverage

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          file: ./**/coverage.xml
          flags: ${{ matrix.service }}
          name: ${{ matrix.service }}-coverage

  # Integration Tests
  test-integration:
    name: Integration Tests
    needs: test-unit
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: test
          POSTGRES_DB: tradesense_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Run Integration Tests
        env:
          DATABASE_URL: postgresql://postgres:test@localhost:5432/tradesense_test
          REDIS_URL: redis://localhost:6379
        run: |
          cd backend
          pip install -r requirements.txt -r requirements-dev.txt
          pytest tests/integration/ -v

  # Build Stage
  build:
    name: Build & Push Images
    needs: [test-unit, test-integration]
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
      id-token: write
    outputs:
      frontend-image: ${{ steps.image.outputs.frontend-image }}
      backend-image: ${{ steps.image.outputs.backend-image }}
      image-digest: ${{ steps.image.outputs.digest }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
            type=sha,prefix={{branch}}-

      - name: Build and push Frontend
        uses: docker/build-push-action@v5
        with:
          context: ./frontend
          push: true
          tags: ${{ steps.meta.outputs.tags }}-frontend
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          provenance: true
          sbom: true

      - name: Build and push Backend
        uses: docker/build-push-action@v5
        with:
          context: ./backend
          push: true
          tags: ${{ steps.meta.outputs.tags }}-backend
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          provenance: true
          sbom: true

      - name: Run Trivy on built images
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: ${{ steps.meta.outputs.tags }}-backend
          format: 'sarif'
          output: 'trivy-image-results.sarif'

      - name: Sign images with Cosign
        env:
          COSIGN_EXPERIMENTAL: "true"
        run: |
          cosign sign --yes ${{ steps.meta.outputs.tags }}-frontend
          cosign sign --yes ${{ steps.meta.outputs.tags }}-backend

      - name: Generate SBOM
        uses: anchore/sbom-action@v0
        with:
          image: ${{ steps.meta.outputs.tags }}-backend
          format: spdx-json
          output-file: sbom.spdx.json

      - name: Set outputs
        id: image
        run: |
          echo "frontend-image=${{ steps.meta.outputs.tags }}-frontend" >> $GITHUB_OUTPUT
          echo "backend-image=${{ steps.meta.outputs.tags }}-backend" >> $GITHUB_OUTPUT
          echo "digest=${{ steps.meta.outputs.digest }}" >> $GITHUB_OUTPUT

  # Infrastructure Validation
  validate-infrastructure:
    name: Validate Infrastructure
    needs: build
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TERRAFORM_VERSION }}

      - name: Terraform Format Check
        run: |
          cd terraform
          terraform fmt -check -recursive

      - name: Terraform Init
        run: |
          cd terraform
          terraform init -backend=false

      - name: Terraform Validate
        run: |
          cd terraform
          terraform validate

      - name: Terraform Security Scan
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'config'
          scan-ref: 'terraform/'
          severity: 'CRITICAL,HIGH'

      - name: Validate Kubernetes Manifests
        run: |
          # Install kubectl
          curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/
          
          # Validate manifests
          find k8s -name "*.yaml" -o -name "*.yml" | xargs kubectl apply --dry-run=client -f

      - name: Validate Helm Charts
        run: |
          # Install helm
          curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
          
          # Validate charts
          helm lint k8s/charts/*

      - name: Run Conftest Policy Validation
        run: |
          # Install conftest
          wget https://github.com/open-policy-agent/conftest/releases/download/v0.46.0/conftest_0.46.0_Linux_x86_64.tar.gz
          tar xzf conftest_0.46.0_Linux_x86_64.tar.gz
          sudo mv conftest /usr/local/bin
          
          # Run policy checks
          conftest verify --policy k8s/policies/ k8s/

  # End-to-End Tests
  test-e2e:
    name: End-to-End Tests
    needs: build
    runs-on: ubuntu-latest
    services:
      k3s:
        image: rancher/k3s:v1.28.3-k3s1
        options: >-
          --privileged
          --cgroupns host
          --volume /sys/fs/cgroup:/sys/fs/cgroup:rw
        ports:
          - 6443:6443
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup test cluster
        run: |
          # Wait for k3s
          sleep 30
          
          # Get kubeconfig
          docker exec $(docker ps -q) cat /etc/rancher/k3s/k3s.yaml > kubeconfig.yaml
          sed -i 's/127.0.0.1/localhost/g' kubeconfig.yaml
          export KUBECONFIG=$PWD/kubeconfig.yaml
          
          # Deploy test environment
          kubectl create namespace e2e-test
          kubectl apply -f k8s/test/ -n e2e-test

      - name: Run E2E Tests
        run: |
          cd frontend
          npm ci
          npm run test:e2e

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: e2e-test-results
          path: |
            frontend/test-results/
            frontend/playwright-report/

  # Load Testing
  load-test:
    name: Load Testing
    needs: [build, test-e2e]
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run k6 Load Test
        uses: grafana/k6-action@v0.3.1
        with:
          filename: tests/load/api-load-test.js
          flags: --out cloud
        env:
          K6_CLOUD_TOKEN: ${{ secrets.K6_CLOUD_TOKEN }}

      - name: Analyze Load Test Results
        run: |
          # Check if performance thresholds were met
          if [ -f "load-test-results.json" ]; then
            python scripts/analyze_load_test.py load-test-results.json
          fi

  # Deploy to Staging
  deploy-staging:
    name: Deploy to Staging
    needs: [validate-infrastructure, load-test]
    runs-on: ubuntu-latest
    environment:
      name: staging
      url: https://staging.tradesense.com
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_DEPLOY_ROLE_ARN }}
          aws-region: us-east-1

      - name: Update Kubernetes manifests
        run: |
          # Update image tags
          sed -i "s|image: .*frontend.*|image: ${{ needs.build.outputs.frontend-image }}|g" k8s/staging/frontend-deployment.yaml
          sed -i "s|image: .*backend.*|image: ${{ needs.build.outputs.backend-image }}|g" k8s/staging/backend-deployment.yaml

      - name: Deploy to Staging
        run: |
          # Setup kubectl
          aws eks update-kubeconfig --name tradesense-staging --region us-east-1
          
          # Apply manifests
          kubectl apply -k k8s/overlays/staging/
          
          # Wait for rollout
          kubectl rollout status deployment/frontend -n tradesense-staging --timeout=5m
          kubectl rollout status deployment/backend -n tradesense-staging --timeout=5m

      - name: Run Smoke Tests
        run: |
          # Wait for services to be ready
          sleep 30
          
          # Run smoke tests
          ./scripts/smoke-test.sh https://staging.tradesense.com

      - name: Performance Baseline
        run: |
          # Run quick performance test
          npx lighthouse https://staging.tradesense.com \
            --output=json \
            --output-path=./lighthouse-staging.json \
            --only-categories=performance

  # Blue-Green Deployment to Production
  deploy-production:
    name: Deploy to Production (Blue-Green)
    needs: [deploy-staging]
    runs-on: ubuntu-latest
    environment:
      name: production
      url: https://tradesense.com
    if: github.ref == 'refs/heads/main'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_DEPLOY_ROLE_ARN }}
          aws-region: us-east-1

      - name: Pre-deployment validation
        run: |
          # Check database migrations
          ./scripts/check-migrations.sh
          
          # Validate configuration
          ./scripts/validate-config.sh production
          
          # Check service dependencies
          ./scripts/check-dependencies.sh

      - name: Create deployment backup
        run: |
          # Backup current deployment
          kubectl get all -n tradesense -o yaml > backup-$(date +%Y%m%d-%H%M%S).yaml
          
          # Trigger database backup
          kubectl create job --from=cronjob/postgres-backup postgres-backup-pre-deploy -n tradesense

      - name: Deploy Green Environment
        run: |
          # Setup kubectl
          aws eks update-kubeconfig --name tradesense-prod --region us-east-1
          
          # Deploy green environment
          sed -i "s|version: blue|version: green|g" k8s/production/*.yaml
          sed -i "s|image: .*frontend.*|image: ${{ needs.build.outputs.frontend-image }}|g" k8s/production/frontend-deployment.yaml
          sed -i "s|image: .*backend.*|image: ${{ needs.build.outputs.backend-image }}|g" k8s/production/backend-deployment.yaml
          
          kubectl apply -f k8s/production/
          
          # Wait for green deployment
          kubectl wait --for=condition=ready pod -l version=green,app=frontend -n tradesense --timeout=5m
          kubectl wait --for=condition=ready pod -l version=green,app=backend -n tradesense --timeout=5m

      - name: Run Production Tests on Green
        run: |
          # Test green environment
          GREEN_URL=$(kubectl get service frontend-green -n tradesense -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
          ./scripts/production-test.sh https://$GREEN_URL

      - name: Progressive Traffic Shift
        run: |
          # Shift 10% traffic to green
          kubectl patch virtualservice frontend -n tradesense --type merge -p '
          {
            "spec": {
              "http": [{
                "route": [
                  {"destination": {"host": "frontend", "subset": "blue"}, "weight": 90},
                  {"destination": {"host": "frontend", "subset": "green"}, "weight": 10}
                ]
              }]
            }
          }'
          
          # Monitor for 5 minutes
          sleep 300
          
          # Check error rate
          ERROR_RATE=$(kubectl exec -n monitoring prometheus-0 -- promtool query instant 'rate(http_requests_total{status=~"5.."}[5m])' | jq -r '.data.result[0].value[1]')
          if (( $(echo "$ERROR_RATE > 0.01" | bc -l) )); then
            echo "High error rate detected, rolling back"
            exit 1
          fi
          
          # Shift 50% traffic
          kubectl patch virtualservice frontend -n tradesense --type merge -p '
          {
            "spec": {
              "http": [{
                "route": [
                  {"destination": {"host": "frontend", "subset": "blue"}, "weight": 50},
                  {"destination": {"host": "frontend", "subset": "green"}, "weight": 50}
                ]
              }]
            }
          }'
          
          # Monitor for 5 minutes
          sleep 300
          
          # Full cutover
          kubectl patch virtualservice frontend -n tradesense --type merge -p '
          {
            "spec": {
              "http": [{
                "route": [
                  {"destination": {"host": "frontend", "subset": "green"}, "weight": 100}
                ]
              }]
            }
          }'

      - name: Finalize Deployment
        run: |
          # Delete blue deployment after successful cutover
          kubectl delete deployment frontend-blue backend-blue -n tradesense
          
          # Update service selectors
          kubectl patch service frontend -n tradesense -p '{"spec":{"selector":{"version":"green"}}}'
          kubectl patch service backend -n tradesense -p '{"spec":{"selector":{"version":"green"}}}'
          
          # Tag release
          git tag -a "v$(date +%Y%m%d-%H%M%S)" -m "Production deployment: ${{ needs.build.outputs.image-digest }}"
          git push origin --tags

      - name: Post-deployment validation
        run: |
          # Run comprehensive health checks
          ./scripts/health-check.sh production
          
          # Run synthetic monitoring
          ./scripts/synthetic-tests.sh
          
          # Check SLOs
          ./scripts/check-slos.sh

      - name: Notify deployment
        if: always()
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          text: |
            Production Deployment ${{ job.status }}
            Commit: ${{ github.sha }}
            Author: ${{ github.actor }}
            Images: ${{ needs.build.outputs.frontend-image }}, ${{ needs.build.outputs.backend-image }}
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK }}

  # Rollback Job (Manual Trigger)
  rollback:
    name: Rollback Production
    runs-on: ubuntu-latest
    environment:
      name: production-rollback
    if: failure()
    needs: deploy-production
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_DEPLOY_ROLE_ARN }}
          aws-region: us-east-1

      - name: Execute Rollback
        run: |
          aws eks update-kubeconfig --name tradesense-prod --region us-east-1
          
          # Restore from backup
          kubectl apply -f backup-*.yaml
          
          # Verify rollback
          kubectl rollout status deployment/frontend -n tradesense
          kubectl rollout status deployment/backend -n tradesense
          
          # Run health checks
          ./scripts/health-check.sh production

      - name: Notify rollback
        uses: 8398a7/action-slack@v3
        with:
          status: custom
          custom_payload: |
            {
              text: "🚨 Production Rollback Executed",
              attachments: [{
                color: 'danger',
                text: 'Production has been rolled back due to deployment failure'
              }]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK }}